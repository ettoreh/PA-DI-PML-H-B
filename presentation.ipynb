{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color='lightskyblue'><center> Projects on Recent Advances in Machine Learning </font></h1> \n",
    "<h1><font color='royalblue'> <center> <strong> Protection de la propriété intellectuelle d'un modèle d'apprentissage profond par tatouage <strong> </font></h1>\n",
    "<h3><font color='skyblue'> <center> 2022 - 2023</font></h2><br>\n",
    "<h6><font><center> Work done by Liu YUDONG, Philippe FOREST and Ettore HIDOUX. Based on the paper \"Embedding watermarks into deep neural networks.\" from Yuki NAGAI, Yusuke UCHIDA, Shigeyuki SAKAZAWA and Shin’ichi SATOH. </font></h4>\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this notebook, is a synthesis of the paper \"Embedding watermarks into deep neural networks.\" with additionnal explainations. In a way to start the second part on developping the algorithm with all the knowledge needed. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Paper Synthesis\n",
    "## 1.0 - Abstract\n",
    "---\n",
    "\n",
    "Lately, performances of deep neural network have increased, it is du to multiple factors: knowledges, pre-trained model that enhanced and make the training faster or fine-tuning. So, the sharing of models will skyrockets the next developments. \n",
    "\n",
    "<strong style=\"color: royalblue;\"> But, how can we consider the intellectual property of those models? </strong>\n",
    "\n",
    "<strong style=\"color: skyblue;\">First</strong>, the article offers to find a way to add embedding watermarks into deep neural networks. \n",
    "\n",
    "<strong style=\"color: skyblue;\">Second</strong>, they proposed a general framework for embedding a watermark in model parameters, using a parameter regularizer that does not affect the performances of models. \n",
    "\n",
    "<strong style=\"color: skyblue;\">Finally</strong>, they performed experiments to reveal the potential of watermarking deep neural networks. The embedded watermark does not disappear even after fine-tuning or parameter pruning (until 65% of parameters are pruned).\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Introduction\n",
    "---\n",
    "Deep neural networks have made high progress in multimedia representation thanks to multiple non-linear transformations, it achives good modelisation. \n",
    "\n",
    "Deep neural networks can be applied to various types of data such as:\n",
    "- sound, \n",
    "- video, \n",
    "- text,\n",
    "- time series,\n",
    "- images. \n",
    "  \n",
    "In particular, deep convolutional neural networks (DCNN) such as LeNet, AlexNet, VGGNet, GoogLeNet, and ResNet have demonstrated remarkable performance for a wide range of computer vision problems and other applications.\n",
    "\n",
    "Additionally, many deep learning frameworks have been released. They help engineers and researchers to develop systems based on deep learning or do research with less effort. Examples of these great deep learning frameworks are Caffe, Theano, Torch, Chainer, TensorFlow, and Keras.\n",
    "\n",
    "Nowadays, few weeks are needed to train a new model with a GPU but in a way to accelerate development some pre-trained models are already available, like Model Zoo provides trained Caffe models. Using those pre-trained models to initialize weights can increase the performances and lower the training time. \n",
    "\n",
    "So, sharing models is important to help researchers, but it also means that <strong style=\"color: royalblue;\"> trained models could be important assets for the owner(s) who trained them </strong>.\n",
    "\n",
    "Finally, the authors argue that trained models could be treated as <strong style=\"color: skyblue;\"> intellectual property </strong>, and they believe that providing <strong style=\"color: skyblue;\"> copyright protection </strong> for trained models is a worthwhile challenge. The article only focus on how to do it and do not discuss about the law regulations possibilities.\n",
    "\n",
    "To this end, we will see how to use a digital watermarking as it is used for images, audios and videos but applied to neural networks. \n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Problem Formulation \n",
    "---\n",
    "Given a model network with or without trained parameters, we define the task of watermark embedding as <strong style=\"color: royalblue;\"> embedding $ T bit\\ vector\\  b ∈ \\{0, 1\\}^T $ into the parameters of one or more layers of the neural network </strong>. \n",
    "\n",
    "The neural network we will apply the watermark will be named the <strong style=\"color: skyblue;\"> host network </strong>, the task the host network is supposed to achived will be named as the <strong style=\"color: skyblue;\"> original task </strong>.\n",
    "\n",
    "1. Requirements for an embedded watermark or an embedding method,\n",
    "2. Embedding situations, \n",
    "3. Expected types of attacks against which embedded watermarks should be robust.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.2.1 Requirements \n",
    "\n",
    "<strong style=\"color: royalblue;\"> Table 1 </strong>: Requirements for an effective watermarking algorithm in the image and neural network domains.\n",
    "\n",
    "|            | Image domain | Neural networks domain |\n",
    "|------------|--------------|------------------------|\n",
    "| Fidelity   | The quality of the host image should not be degraded by embedding a watermark. | The effectiveness of the host network should not be degraded by embedding a watermark. |\n",
    "| Robustness | The embedded watermark should be robust against common signal processing operations such as lossy compression, cropping, resizing, and so on. | The embedded watermark should be robust against model modifications such as fine-tuning and model compression. |\n",
    "| Capacity   | An effective watermarking system must have the ability to embed a large amount of information.                 | same |\n",
    "| Security   | A watermark should in general be secret and should not be accessed, read, or modified by unauthorized parties. | same |\n",
    "| Efficiency | The watermark embedding and extraction processes should be fast.                                               | same |\n",
    "\n",
    "### 1.2.2 Embedding Situations\n",
    "\n",
    "<strong style=\"color: royalblue;\"> Table 2 </strong>: Three embedding situations. Fine-tune indicates whether parameters are initialized in embedding using already trained models, or not. Label availability indicates whether or not labels for training data are available in embedding.\n",
    "\n",
    "<strong style=\"color: skyblue;\"> Train-to-embed </strong>, the host network is trained from scratch.\n",
    "<strong style=\"color: skyblue;\"> Fine-tune-to-embed </strong>,  a watermark is embedded while fine-tuning, model parameters are initialized with a pre-trained network.\n",
    "<strong style=\"color: skyblue;\"> Distill-to-embed </strong>,  a watermark is embedded into a trained network without labels using the\n",
    "distilling approach. Embedding is performed in fine-tuning where the predictions of the trained model are used as labels.\n",
    "\n",
    "|                     | Fine-tune | Label availability |\n",
    "|---------------------|-----------|--------------------|\n",
    "| Train-to-embed      |           | X                  |\n",
    "| Fine-tune-to-embed  | X         | X                  |\n",
    "| Distill-to-embed    | X         |                    |\n",
    "\n",
    "### 1.2.3 Expected types of attacks\n",
    "\n",
    "Related to the requirement for robustness in Section <strong style=\"color: skyblue;\"> 1.2.1 </strong>, we assume three types of attacks against which embedded watermarks should be robust: \n",
    "- fine-tuning, \n",
    "- model compression,\n",
    "- watermark overwriting\n",
    "\n",
    "#### 1.2.3.1 Fine-tuning\n",
    "\n",
    "<strong style=\"color: royalblue;\"> Fine-tuning </strong> is mostly used in practice instead of training a model from scratch, it is trained models that are used to initiate weights, it helps to reduce both the computational cost and improve the performance. So, the watermark has to resist the alteration generated by fine-tuning </strong>, eitehr it is intentionally or unintentionally.\n",
    "\n",
    "#### 1.2.3.2 Model Compression\n",
    " \n",
    "<strong style=\"color: royalblue;\"> Model compression </strong> is very important in deploying deep neu-ral networks in embedded systems or mobile devices as it can significantly reduce memory requirements and/or computational cost. As for image compression, lossy compression distorts model parameters, so we should explore how it affects the detection rate.\n",
    "\n",
    "#### 1.2.3.3 Watermark Overwriting\n",
    "\n",
    "<strong style=\"color: royalblue;\"> Watermark overwriting </strong> would be a severe attack. Attackers may try to destroy an existing watermark by embedding different watermark in the same manner. Ideally embedded watermarks should be robust against this type of attack.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Proposed Framework \n",
    "---\n",
    "In the article, they propose a framework for embedding a watermark into a host network. Although they focus on a DCNN as the host, but could be on a standard multilayer perceptron (MLP), recurrent neural networks (RNN), and long short-term memory (LSTM).\n",
    "\n",
    "Through:\n",
    "1. Embedding Targets\n",
    "2. Embedding Regularizer\n",
    "3. Regularizer Parameters\n",
    "\n",
    "<strong style=\"color: red;\"> Work Idea </strong>: try another network\n",
    "\n",
    "### 1.3.1 Embedding Targets\n",
    "\n",
    "In this paper, a watermark is assumed to be embedded into one of the convolutional layers in a host DCNN. \n",
    "- (S, S) is the size of the convolution filter\n",
    "- D is the depth of input to the convolutional layer\n",
    "- L is the number of filters in the convolutional layer\n",
    "- W ∈ $R^{S×S×D×L}$ is a parameters tensor of this convolutional layer\n",
    "- T is the size of the vector to embedd into W\n",
    "- \n",
    "\n",
    "The bias term is ignored here.\n",
    "Let us think of embedding a $ Tbit\\ vector\\ b\\ ∈ \\{0, 1\\}^T $ into W .\n",
    "The tensor W is a set of L convolutional filters and the or-\n",
    "der of the filters does not affect the output of the network\n",
    "if the parameters of the subsequent layers are appropriately\n",
    "re-ordered. In order to remove this arbitrariness in the or-\n",
    "der of filters, we calculate the mean of W over L filters as\n",
    "Wijk = 1\n",
    "L\n",
    "∑\n",
    "l Wijkl. \n",
    "\n",
    "- b is a $ Tbit\\ vector\\ b\\ ∈ \\{0, 1\\}^T \n",
    "- w ∈ $ R^M (M = S × S × D) $ denote a flattened version of W \n",
    "  \n",
    "<strong style=\"color: skyblue;\"> Our objective is now to embed T -bit vector b into w. <strong>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Experiments \n",
    "---\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x = \\frac {-b \\pm \\sqrt{b^2 - 4ac}}{2a}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Experiments\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Discussion\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Conclusions\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "bada3f752f9ffb4a36e22b9957204165790d2a352948163d32c044c30f2f6ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
